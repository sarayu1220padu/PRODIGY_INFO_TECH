# PRODIGY_INFO_TECH
# Welcome to the Prodigy InfoTech Data Science Internship Repository! 👩‍💻📊

This repository is a comprehensive collection of the tasks and projects I completed during my **Data Science Internship at Prodigy InfoTech**. Each task is aimed at enhancing my skills in Python programming, data visualization, machine learning, and real-world data analysis. All projects were implemented using **Google Colab** and popular Python libraries like **Pandas**, **Matplotlib**, **Seaborn**, and **Scikit-learn**.

---

## 📂 Table of Contents

- [Introduction](#introduction)
- [Tasks Overview](#tasks-overview)
  - [Task 01: WORLD_BANK_ANALYSIS📊](#Task-01-WORLD_BANK_ANALYSIS-)
  - [Task 02: TITANIC_SURVIVAL_PREDICTION 🚢](#Task-02-TITANIC_SURVIVAL_PREDICTION-)
  - [Task 03: BANK_MARKETING_ANALYSIS🔍💼](#Task-03-BANK_MARKETING_ANALYSIS-)
  - [Task 04: TWITTER_SENTIMENT_ANALYSIS💬](#Task-04-TWITTER_SENTIMENT_ANALYSIS-)
  - [Task 05: US_ACCIDENTS_ANALYSIS 🚧](#Task-05-US_ACCIDENTS_ANALYSIS-)
- [Thanking Prodigy InfoTech](#Thanking-Prodigy-InfoTech)

---

## 🔍 Introduction

During my internship at **Prodigy InfoTech**, I completed a variety of tasks designed to simulate real-world data science scenarios. These tasks gave me hands-on experience with data cleaning, visualization, machine learning models, and exploratory data analysis (EDA). This repository is organized to showcase my technical growth and project contributions throughout the internship.

---

## 📈 Tasks Overview

### ✅ TASK 01:  WORLD_BANK_ANALYSIS 📊

- **Description:**  
  Created visualizations to represent distributions of categorical or continuous variables, such as age or gender distribution.

- **Tools Used:** Python, Google Colab, Matplotlib, Seaborn  
- **Folder:** `Task-01_WORLD_BANK_ANALYSIS`

---

### ✅ TASK 02: TITANIC_SURVIVAL_PREDICTION 🚢

- **Description:**  
  Performed data cleaning and exploratory data analysis on the Titanic dataset. Identified patterns related to survival, age, and class.

- **Tools Used:** Python, Pandas, Seaborn, Matplotlib  
- **Folder:** `Task-02_TITANIC_SURVIVAL_PREDICTION`

---

### ✅ TASK 03: BANK_MARKETING_ANALYSIS 🔍💼

- **Description:**  
  Built a Decision Tree Classifier to predict customer purchase behavior using demographic and behavioral features. The model was trained on the Bank Marketing dataset from UCI.

- **Tools Used:** Python, Scikit-learn, Pandas, Google Colab  
- **Folder:** `Task-03_BANK_MARKETING_ANALYSIS`

---

### ✅ TASK 04: TWITTER_SENTIMENT_ANALYSIS 💬

- **Description:**  
  Analyzed sentiment patterns in Twitter data to understand public opinion and attitudes toward specific topics or brands using basic NLP techniques.

- **Tools Used:** Python, Pandas, Matplotlib, Seaborn, NLP libraries  
- **Folder:** `Task-04_ TWITTER_SENTIMENT_ANALYSIS`

---

### ✅ TASK 05: US_ACCIDENTS_ANALYSIS🚧

- **Description:**  
  Explored traffic accident datasets to uncover patterns related to weather, road conditions, and time. Visualized accident hotspots and contributing factors.

- **Tools Used:** Python, Seaborn, Matplotlib, Google Colab  
- **Folder:** `Task-05_US_ACCIDENTS_ANALYSIS`

---

## 🙏 Thanking Prodigy InfoTech

I would like to extend my sincere thanks and gratitude to the entire **Prodigy InfoTech** team for providing me with this incredible opportunity to be a part of their internship program. The experience gained during this internship has been invaluable, and I am grateful for the guidance, mentorship, and support I received from **Prodigy InfoTech's team**. **Prodigy InfoTech** has not only deepened my technical expertise in Python programming but also given me exposure to real-world projects and a collaborative work environment, which will undoubtedly benefit my future career. Once again, thank you to **Prodigy InfoTech** for this fantastic internship experience!

---

📌 *Note: Each task is stored in its respective folder for easy navigation. All code is written in Python and executed using Google Colab.*
